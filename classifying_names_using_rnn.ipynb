{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8L1mGf0iUNICqnJRPMoU2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DotSlash-A/Pytorch/blob/main/classifying_names_using_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2Hil_3_lR8z",
        "outputId": "02ad69b2-bcd9-4cd9-a715-220bd7f69d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-29 10:59:13--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 108.156.60.129, 108.156.60.77, 108.156.60.94, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|108.156.60.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-09-29 10:59:14 (93.0 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI_VZXlSl6ou",
        "outputId": "9e9ad478-37ed-4f3b-82a2-1e3b34e6c3bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "aRwTmQaPmlL2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "print(findFiles('data/names/*.txt'))\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Gj6lSqmC8t",
        "outputId": "4957f34b-646f-41b5-9054-94b0eb977f04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data/names/Scottish.txt', 'data/names/Spanish.txt', 'data/names/German.txt', 'data/names/French.txt', 'data/names/Chinese.txt', 'data/names/Italian.txt', 'data/names/Czech.txt', 'data/names/Irish.txt', 'data/names/English.txt', 'data/names/Polish.txt', 'data/names/Portuguese.txt', 'data/names/Japanese.txt', 'data/names/Vietnamese.txt', 'data/names/Korean.txt', 'data/names/Dutch.txt', 'data/names/Greek.txt', 'data/names/Russian.txt', 'data/names/Arabic.txt']\n",
            "Slusarski\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_lines['Korean']"
      ],
      "metadata": {
        "id": "Wl-_ZMiBmMcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def letter_to_tensor(letter):\n",
        "  n=len(letter)\n",
        "  y=torch.zeroes(1,n)\n",
        ""
      ],
      "metadata": {
        "id": "FXzviVQqmVVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find letter index from all_letters, e.g. \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "GyupIDz1nL0c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(letterToTensor('J'))\n",
        "print(lineToTensor('Jones').size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeqyqttxnOQq",
        "outputId": "df229580-2eaf-45d3-9868-c092ec9a12a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]])\n",
            "torch.Size([5, 1, 57])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "KyvGoX7FnPBm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 128"
      ],
      "metadata": {
        "id": "6WRfnsE9nlbD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "      super(RNN, self).__init__()\n",
        "      self.hidden_size=hidden_size\n",
        "\n",
        "      self.i_to_h=nn.Linear(input_size+hidden_size,hidden_size)\n",
        "      self.h_to_o=nn.Linear(hidden_size,output_size)\n",
        "      self.softmax=nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "      combined=torch.cat((input,hidden),1)\n",
        "      hidden=self.i_to_h(combined)\n",
        "      output=self.h_to_o(hidden)\n",
        "      return self.softmax(output)\n",
        "\n",
        "\n",
        "    def initHidden(self):\n",
        "      tensor = torch.zeros(1, self.hidden_size)\n",
        "      return tensor\n"
      ],
      "metadata": {
        "id": "vC3KvnnRnlvf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(n_letters,n_hidden,n_categories)"
      ],
      "metadata": {
        "id": "Eu3WjOtKqNie"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Ln9RAEXqXj0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}